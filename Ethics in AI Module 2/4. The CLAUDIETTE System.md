CLAUDIETTE che fa?
Automatically detect potentially unfair clauses in Terms of Services and Privacy Policies
![[Pasted image 20240603225549.png]]
Su queste 50 ToS hanno categorizzato le clausule al loro interno secondo diversi tipi di clausole. 
Hanno poi assegnato a ognuna di esse un **parere su quanto fossero GIUSTE**.
Quindi si hanno clausole
1. clearly fair
2. potentially unfair
3. clearly unfair
I tipi di clausola sono elencati in figura e c'e' anche il numero di queste clausole all'interno di questi 50 ToS, insieme al numero di documenti all'interno dei quali queste compaiono.

![[Pasted image 20240604211529.png]]
Ora andro' per ognuno di questo tipo di clausole a far degli esempi:
## CONTRACT BY USING
If a clause states that the consumer is bound by the terms of service simply by visiting the website or by downloading the app, or by using the service: **potentially unfair**
A potentially unfair consent by using clause (Airbnb):
`<use2> By accessing or using the Airbnb Platform, you agree to comply with and be bound by these Terms of Service.<use2>`
### Also for the privacy
Whenever a clause states (or it might be possible to assume) that the consumer *consents* to the privacy policy *simply by using the service*: **potentially unfair**
![[Pasted image 20240604213251.png]]
## JURISDICTION
In queste clausole e' scritta la risposta alla domanda  **Where a dispute will be adjudicated?**
1. If giving consumers a right to bring disputes in their place of residence: **clearly fair**
2. If stating that any judicial proceeding takes a residence away (i.e. in a different city, different country): **clearly unfair**

![[Pasted image 20240604211951.png]]

## CHOICE OF LAW
In queste clausole c'e' scritta la risposta alla domanda **What law will be applied in potential adjudication of a dispute arising under the contract?** 
1. If the applicable law is the law of the consumer’s country of residence => **clearly fair**
2. In every other case, the choice of law clause was considered as => **potentially unfair**
![[Pasted image 20240604212118.png]]
## LIMITATION OF LIABILITY
In queste clausole c'e' scritta la risposta alla domanda **For what actions/events the provider claims they will not be liable (responsabile)?**
1. If stating that the provider may be liable: **clearly fair**
2. If stating that the provider will never be liable for **any action taken by other people**, damages incurred by the computer **because of malware**, when contains a blanket phrase like **“to the fullest extent permissible by law”**: **potentially unfair**
3. If stating that the provider will never be liable for physical injuries (health/life), gross negligence, intentional damage: **clearly unfair**
![[Pasted image 20240604212621.png]]
![[Pasted image 20240604212637.png]]

## UNILATERAL TERMINATION
1. If the provider has the right to suspend and/ or terminate the service and/or the contract, and the reasons are specified => **potentially unfair**
2. If the provider has the right to suspend and/ or terminate the service and/or the contract, at any time for any or no reasons and/or without notice => **clearly unfair**
![[Pasted image 20240604212752.png]]

## CONTENT REMOVAL
1. If the provider has the right to modify/delete user’s content, including in-app purchases, and the conditions under which the service provider may do so are specified => **potentially unfair** 
2. If the provider may remove content in his full discretion, and/or at any time for any or no reasons and/or without notice nor possibility to retrieve the content => **clearly unfair**
![[Pasted image 20240604212932.png]]
## UNILATERAL CHANGE
If the provider has the right to modify the terms of service and/or the service itself => **potentially unfair**
![[Pasted image 20240604213030.png]]
## ARBITRATION
In queste clausole c'e' scritta la risposta alla domanda : **Is arbitration mandatory before the case can go to court?**

1. If arbitration is fully optional: **clearly fair**
2. If arbitration should take place in a state other then the state of consumer’s residence and/or be based on arbiter’s discretion (i.e. not on law): **clearly unfair**
3. All other arbitration clauses: **potentially unfair**
![[Pasted image 20240604213522.png]]

# MACHINE LEARNING APPROACH
Hanno risolto due tasks:
1. **detection task**: data una frase in input il modello creato e allenato e' in grado di capire se questa contiene una **clausola potenzialmente ingiusta** al suo interno
2. **sentence classification task**: qual e' la categoria a cui appartiene questa clausola? 

![[Pasted image 20240604214104.png]]
Questi sono i risultati per ogni categoria, per la **sentence classification task**:
![[Pasted image 20240604214231.png]]

Internamente sto CLAUDIETTE in verita' funziona anche meglio, perche' ha una Knowledge Based e quindi permette di dare una spiegazione per le predizioni che vengono fatte:
Di base, prima che un ToS (**una query**) venga passato come input del modello per ottenere un output che mi dica se contiene clausole **potentially unfair** e **che tipo di clausole ha al suo interno** viene prima fatto un match della query con una KB, nel seguente modo:
![[Pasted image 20240604221930.png]]
Questo approccio e' chiamato **memory augumented neural network**. In input si da' poi qualcosa risultante dall'aver aggregato il ToS con la KB matchata.

Per ogni tipo di clausola ho degli IDs nella KB ad essa associati. Ad esempio per la *LIMITING LIABILITY* ho 6 classi diverse di IDs corrispondenti a diversi tipi di *LIMITING LIABILITY* per l'appunto. Al loro interno hanno degli IDs. A ognuno e' associata una descrizione di **quello specifico tipo di clausola.**

**parte in cui mi immagino come l'hanno implementata perche' non presente sulle slides**
In sto modo mi immagino che parte del testo venga matchata a degli IDs, e quella parte del testo insieme al testo legato a quegli IDs viene poi messa come input per predirre. La risposta e' la categoria risultante e se e' fair o unfair. A quel punto in caso di unfair viene mostrato per ogni ID la percentuale di score di match con il testo e viene printato il testo legato alla knowledge base di quell'ID 

### MULTILINGUAL CLAUDIETTE
Per renderlo multilingua hanno dovuto ricreare i datasets per le lingue *tedesco, italiano, polacco*.
Per fare cio' le opzioni erano quattro. Il problema e' annotare perche' i ToS nelle varie lingue sono disponibili da subito, sono le labels a non esserlo. Si prenda in esempio la lingua tedesca. 
1.  Ogni documento corrispondente a un ToS in lingua tedesca **viene annotato manualmente**
2. ![[Pasted image 20240604223902.png]]
3. ![[Pasted image 20240604223927.png]]
4. Tutto uguale, non c'e' bisogno di fare alcun **retrain** come nei casi di sopra. L'unica cosa che viene fatta e' che a test time il documento in tedesco viene tradotto in inglese tramite machine translation, viene dato in pasto a CLAUDIETTE e l'output viene tradotto dall'inglese al tedesco in output
 ![[Pasted image 20240604224033.png]]
 Results across the three languages consistently indicate that the fourth scenario (i.e., keeping only the Eng version of the machine learning system, relying on the translation of the queries at test time, is the best solution when the translation system has a high quality

# CLAUDIETTE e il GDPR
E' stato fatto anche un CLAUDIETTE per, dato un testo, vedere se rispettava o meno le norme del GDPR.
FIGO onestamente.

Secondo il GDPR, analizzando una **policy** di un qualche servizio/di una qualche applicazione si devono avere le seguenti cose:
1. **Comprehensiveness of Information**: la policy deve contenere tutte le informazioni rischieste dagli articoli 13 e 14 del GDPR
2. **Clarity of expression**: la policy deve essere scritta seguendo un linguaggio comprensibile e preciso
3. **Substantive compliance**: la policy deve permettere SOLO il processing dei dati personali consentito dal GDPR

## Comprehensiveness of Information
Io voglio analizzare tutte quelle righe della policy che sono legate a informazioni relative alla collezione dei dati personali del data subject (quindi relative all'articolo 13 e 14 del GDPR).
Ci sono diversi tipi di informazioni richieste dal GDPR, e sono espresse qua sotto:
![[Pasted image 20240605152259.png]]

A seconda della risposta legata a queste informazioni si puo' affermare se quel tipo di informazione rispetta o meno le norme del GDPR dell'articolo 13 e 14.

### Categories of personal data concerned
Per esempio, se prendiamo in considerazione questo tipo di informazione richiesta, posso avere:
1. clauses where the categories of personal data are comprehensively specified and not vague, e in questo caso ho una **informazione completa**
2. In other cases (e.g. when a clause only provides examples) ho **un'informazione non sufficiente**
![[Pasted image 20240605152935.png]]
Tipo in sta clausola di Google, ci sono solo **esempi**, quindi la descrizione di quali informazioni vengono collezionate e' **vaga**.

## Substantiative Compliance
In questa macro categoria rientrano tutte quelle clausole legate al processing dei dati personali. Queste si dividono in diversi tipi:
![[Pasted image 20240605153143.png]]
### Policy change
Se prendiamo in esame questo TIPO di clausola, per vedere se c'e' o meno una conformita' sostanziale  si va a vedere cosa e' contenuto in questo tipo di clausola.
Quando si parla del cambio della policy nella policy stessa:
1. When notice is given and new consent is required: **fair processing clause**
2. When notice is given but a new consent (or confirmation of reading) is not required: **problematic processing clause**
![[Pasted image 20240605153419.png]]
In sto caso ti notificano ma non c'e' bisogno di un nuovo consenso. Basta quello precedente (il che e' problematico)
3. When no notice is given and new consent is not required: **unfair processing clause**
![[Pasted image 20240605153457.png]]
## Clarity of expression
SI richiede che le clausole siano scritte in modo chiaro e non vago.
**Is the privacy policy framed in an understandable and precise language?**
Ci sono 4 indicatori:
1. ![[Pasted image 20240605153647.png]]
2. ![[Pasted image 20240605153716.png]]
3. ![[Pasted image 20240605153730.png]]
4. ![[Pasted image 20240605153744.png]]

![[Pasted image 20240605153825.png]]

![[Pasted image 20240605153851.png]]

SI e' pensato addirittua di dare queste policies in pasto a un Large Language Model in modo da poter lui decretare se sono consone o meno rispetto alle cose viste sopra, se quindi rispettano il GDPR e non sono vaghe.

# Comprehensiveness vs Comprehensibility
Ci sono due forze che giocano sulle **policies**. e sono le seguenti:
![[Pasted image 20240605154825.png]]

Infatti le policies devono essere sia piene di informazioni che comprensibili (quindi scritte in modo chiaro e semplice) proprio a livello LEGALE entrambe le cose ci devono essere.
## Comprehensiveness nel GDPR
Ci sono varie cose che per legge, seguendo il GDPR devono essere per forza specificate in una policy e sono legate alla trasparenza, ovvero:
![[Pasted image 20240605155029.png]]
 Nel giudicare una policy dovremmo farci le seguenti domande:
 ![[Pasted image 20240605155358.png]]
# VALUTARE/GIUDICARE UNA POLICY
## Scenario 1: Valutazione da parte di UMANI di policies gia' esistenti
![[Pasted image 20240605160033.png]]
I risultati sono i seguenti, sulle 9 domande:
![[Pasted image 20240605160118.png]]
Esempi di vaghezza nelle policies sono i seguenti:
![[Pasted image 20240605160210.png]]
Nasce spontanea la seguente PROPOSTA di legge:
``The law should require corporations to disclose fully comprehensive privacy policies ideally in a standardized form relax the comprehensibility requirement.``
Si dovrebbe applicare a ogni categoria il **non ambiguity test**: if it is reasonably possible for a reader to ask “but what do you mean by category X?”, that category should either be split into smaller categories or exhaustively defined


## Scenario 2: LLMs e Mock Privacy Policy

Si son scritti questi Mock Privacy Policy che sono delle policies in cui tutto e' scritto in maniera CHIARA, dall'inizio alla fine. Un esempio e' questo
![[Pasted image 20240605161213.png]]
E niente si da' in pasto al LLM e si vuole vedere se questo LLM e' in grado o meno di rispondere a queste 9 domande.
![[Pasted image 20240605161309.png]]

Si sono utilizzate come metriche la *precision*, la *recall* e l'*f1*. Come? Perche' per ogni risposta data dal LLM, dei **legal experts** hanno decretato o meno se la risposta data dalla LLM fosse CORRETTA, e rispondesse effettivamente alla domanda fatta nel prompt in modo coerente con quello che c'e' scritto nella Mock Policy. Quindi se ho per esempio che nel Mock Policy e' presente il testo per rispondere a una domanda e la risposta della LLM non fa alcun riferimento a quel testo allora ho un False Negative (perche' in verita' la risposta era presente). Se invece il testo per rispondere NON e' presente, e la LLM risponde usando del testo che non c'e' allora ho un False Positive (perche' la risposta in verita' non c'era nel testo della mock policy). Se si ha che la risposta non c'e' nel Mock PP e la LLM dice che EFFETTIVAMENTE non c'e' allora ho un TN. SE la risposta c'e' e il LLM la trova allora ho un TP.
![[Pasted image 20240605161717.png]]
GPT answered the majority of questions correctly (33 of 45 questions).
Nota che l'input e' SEMPRE LA STESSA POLICY. Il prompt viene runnato per tutte e 9 le domande. Tutto questo per 5 volte per vedere se magari in run diverse ho un diverso risultato.

![[Pasted image 20240605162356.png]]
Llama2-7B ha fatto cagare altamente.

## Scenario 3:LLMs and Real Privacy Policies
![[Pasted image 20240605162902.png]]
Un esempio di come e' andata e' il seguetne
![[Pasted image 20240605163734.png]]
Ho che CHAT-GPT inferisce la risposta dal testo (infatti c'e' il tag INF). Llambda2-7B invece ALLUCINA PESANETMENETE inventandosi che l'address venga collezionato per un massimo di 1 anno (infatti il tag e' HAL).

I risultati sono i seguetni
![[Pasted image 20240605164028.png]]

CHAT-GPT almeno non ha allucinato (cio' significa che quando ho FP ha preso delle informaizoni presenti/scritte nella policy ma che **erano ininfluenti per quella specifica risposta**, o che non c'entravano niente).
In st'altro esempio si vedono due cose
![[Pasted image 20240605164257.png]]
1. Chat-GPT 4 e' FN perche' NON mette delle informazioni nella risposta che sarebbero dovute esserci quali **il nome degli altri recipiets, come Merchants**. 
2. Llambda2-7B Fa un macello perche' nella risposta ALLUCINA inserendo cose che non sono presenti nella policy in input, presenta anche dei FP perche' per rispondere utilizza altri pezzi della PP che non c'entrano con la domanda posta , e ha anche dei FN perche' non mette nella risposta delle informazioni presenti nella PP che servivano per rispondere correttamente alla domanda.
 ![[Pasted image 20240605164654.png]]
 LE CONCLUSIONI SONO LE SEGUETNI:
 ![[Pasted image 20240605164800.png]]
 Cioe' bro i PP esistenti fanno caha, di base neanche gli esperti riescono a rispondere alle domande. Sono formulati cosi' male che gli LLM non riescono a estrarre correttamente informazioni da esse, mentre riescono con PP formulati bene con un modo di scrivere chiaro e non vago.